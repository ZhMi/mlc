{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2d8f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorIR 练习\n",
    "# https://mlc.ai/zh/chapter_tensor_program/tensorir_exercises.html#id1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "469c5a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 练习1：请编写一个 TensorIR 函数，将两个数组以广播的方式相加。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71c9c499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "import numpy as np\n",
    "import tvm\n",
    "from tvm.script import tir as T\n",
    "from tvm.ir.module import IRModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "617f481b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  4,  4,  4],\n",
       "       [ 8,  8,  8,  8],\n",
       "       [12, 12, 12, 12],\n",
       "       [16, 16, 16, 16]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init data\n",
    "\n",
    "a = np.arange(16).reshape(4, 4)\n",
    "b = np.arange(4, 0, -1).reshape(4)\n",
    "\n",
    "# numpy version\n",
    "c_np = a + b\n",
    "c_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "813b15e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.,  4.,  4.,  4.],\n",
       "       [ 8.,  8.,  8.,  8.],\n",
       "       [12., 12., 12., 12.],\n",
       "       [16., 16., 16., 16.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# python version\n",
    "def lnumpy_broadcast_add(a: np.ndarray, b: np.ndarray, c: np.ndarray):\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            c[i, j] = 0\n",
    "            c[i, j] = a[i, j] + b[j]\n",
    "#test lnumpy_broadcast_add\n",
    "c_lbro_add = np.zeros((4, 4))\n",
    "lnumpy_broadcast_add(a, b, c_lbro_add)\n",
    "c_lbro_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "265126ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#请完成以下 IRModule MyAdd 并运行代码以检查你的实现。\n",
    "@tvm.script.ir_module\n",
    "class MyAdd:\n",
    "  @T.prim_func\n",
    "  def add(A: T.Buffer[(4, 4), \"int64\"],\n",
    "          B: T.Buffer[(4), \"int64\"],\n",
    "          C: T.Buffer[(4, 4), \"int64\"]):\n",
    "    T.func_attr({\"global_symbol\": \"add\", \"tir.noalias\": True})\n",
    "    # TODO\n",
    "    for i, j in T.grid(4, 4):\n",
    "        with T.block(\"C\"):\n",
    "            vi = T.axis.spatial(4, i)\n",
    "            vj = T.axis.spatial(4, j)\n",
    "            C[vi, vj] = A[vi, vj] + B[vj]\n",
    "\n",
    "rt_lib = tvm.build(MyAdd, target=\"llvm\")\n",
    "a_tvm = tvm.nd.array(a)\n",
    "b_tvm = tvm.nd.array(b)\n",
    "c_tvm = tvm.nd.array(np.empty((4, 4), dtype=np.int64))\n",
    "rt_lib[\"add\"](a_tvm, b_tvm, c_tvm)\n",
    "np.testing.assert_allclose(c_tvm.numpy(), c_np, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14c8babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 练习2：二维卷积\n",
    "# 其中，\n",
    "# A 是输入张量，W 是权重张量，b 是批次索引，k 是输出通道， i 和 j 是图像高度和宽度的索引，di 和 dj 是权重的索引 \n",
    "# q 是输入通道，strides 是过滤器窗口的步幅\n",
    "# 在练习中，我们选择了一个小而简单的情况，即 stride=1, padding=0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53de19f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight: [[[[ 0  1  2]\n",
      "   [ 3  4  5]\n",
      "   [ 6  7  8]]]\n",
      "\n",
      "\n",
      " [[[ 9 10 11]\n",
      "   [12 13 14]\n",
      "   [15 16 17]]]]\n",
      "data: [[[[ 0  1  2  3  4  5  6  7]\n",
      "   [ 8  9 10 11 12 13 14 15]\n",
      "   [16 17 18 19 20 21 22 23]\n",
      "   [24 25 26 27 28 29 30 31]\n",
      "   [32 33 34 35 36 37 38 39]\n",
      "   [40 41 42 43 44 45 46 47]\n",
      "   [48 49 50 51 52 53 54 55]\n",
      "   [56 57 58 59 60 61 62 63]]]]\n"
     ]
    }
   ],
   "source": [
    "N, CI, H, W, CO, K = 1, 1, 8, 8, 2, 3\n",
    "OUT_H, OUT_W = H - K + 1, W - K + 1\n",
    "# data-shape [1, 1, 8, 8]\n",
    "data = np.arange(N*CI*H*W).reshape(N, CI, H, W)\n",
    "# weight-shape [2, 1, 3, 3]\n",
    "weight = np.arange(CO*CI*K*K).reshape(CO, CI, K, K)\n",
    "print (\"weight:\", weight)\n",
    "print (\"data:\",  data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2b5c83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 474,  510,  546,  582,  618,  654],\n",
       "         [ 762,  798,  834,  870,  906,  942],\n",
       "         [1050, 1086, 1122, 1158, 1194, 1230],\n",
       "         [1338, 1374, 1410, 1446, 1482, 1518],\n",
       "         [1626, 1662, 1698, 1734, 1770, 1806],\n",
       "         [1914, 1950, 1986, 2022, 2058, 2094]],\n",
       "\n",
       "        [[1203, 1320, 1437, 1554, 1671, 1788],\n",
       "         [2139, 2256, 2373, 2490, 2607, 2724],\n",
       "         [3075, 3192, 3309, 3426, 3543, 3660],\n",
       "         [4011, 4128, 4245, 4362, 4479, 4596],\n",
       "         [4947, 5064, 5181, 5298, 5415, 5532],\n",
       "         [5883, 6000, 6117, 6234, 6351, 6468]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch version\n",
    "import torch\n",
    "\n",
    "data_torch = torch.Tensor(data)\n",
    "weight_torch = torch.Tensor(weight)\n",
    "conv_torch = torch.nn.functional.conv2d(data_torch, weight_torch)\n",
    "conv_torch = conv_torch.numpy().astype(np.int64)\n",
    "conv_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08745ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 474.,  510.,  546.,  582.,  618.,  654.],\n",
       "         [ 762.,  798.,  834.,  870.,  906.,  942.],\n",
       "         [1050., 1086., 1122., 1158., 1194., 1230.],\n",
       "         [1338., 1374., 1410., 1446., 1482., 1518.],\n",
       "         [1626., 1662., 1698., 1734., 1770., 1806.],\n",
       "         [1914., 1950., 1986., 2022., 2058., 2094.]],\n",
       "\n",
       "        [[1203., 1320., 1437., 1554., 1671., 1788.],\n",
       "         [2139., 2256., 2373., 2490., 2607., 2724.],\n",
       "         [3075., 3192., 3309., 3426., 3543., 3660.],\n",
       "         [4011., 4128., 4245., 4362., 4479., 4596.],\n",
       "         [4947., 5064., 5181., 5298., 5415., 5532.],\n",
       "         [5883., 6000., 6117., 6234., 6351., 6468.]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# python version \n",
    "def lnumpy_conv(a_in: np.ndarray, b_in: np.ndarray, c_out: np.ndarray):\n",
    "    for b in range(1):\n",
    "        for k in range(2):\n",
    "            for i in range(6):\n",
    "                for j in range(6):\n",
    "                    for q in range(1):\n",
    "                        if q == 0:\n",
    "                            c_out[b, k, i, j] = 0\n",
    "                        for di in range(3):\n",
    "                            for dj in range(3):\n",
    "                                c_out[b,k,i,j] += a_in[b, q, i + di, j + dj] * b_in[k, q, di, dj]\n",
    "                                \n",
    "c_lnumpy_conv = np.zeros((1, 2, 6, 6))\n",
    "lnumpy_conv(data, weight, c_lnumpy_conv)\n",
    "c_lnumpy_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3001779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#请完成以下 IRModule MyConv 并运行代码以检查您的实现。\n",
    "@tvm.script.ir_module\n",
    "class MyConv:\n",
    "  @T.prim_func\n",
    "  def conv(A: T.Buffer[(1, 1, 8, 8), \"int64\"],\n",
    "           B: T.Buffer[(2, 1, 3, 3), \"int64\"],\n",
    "           C: T.Buffer[(1, 2, 6, 6), \"int64\"]):\n",
    "    T.func_attr({\"global_symbol\": \"conv\", \"tir.noalias\": True})\n",
    "    # TODO\n",
    "    # 不能是 b，只能是b_0, 避免和T.Buffer->B发生命名冲突\n",
    "    for b_0, k, i, j, q, di, dj in T.grid(1, 2, 6, 6, 1, 3, 3):\n",
    "        with T.block(\"C\"):\n",
    "            vb_0, vk, vi, vj, vq, vdi, vdj = T.axis.remap(\"SSSSRRR\",[b_0, k, i, j, q, di, dj])\n",
    "            with T.init():\n",
    "                C[vb_0, vk, vi, vj] = T.int64(0)\n",
    "            C[vb_0, vk, vi, vj] = C[vb_0, vk, vi, vj] + A[vb_0, vq, vi + vdi, vj + vdj] * B[vk, vb_0, vdi, vdj]    \n",
    "rt_lib = tvm.build(MyConv, target=\"llvm\")\n",
    "data_tvm = tvm.nd.array(data)\n",
    "weight_tvm = tvm.nd.array(weight)\n",
    "conv_tvm = tvm.nd.array(np.empty((N, CO, OUT_H, OUT_W), dtype=np.int64))\n",
    "rt_lib[\"conv\"](data_tvm, weight_tvm, conv_tvm)\n",
    "np.testing.assert_allclose(conv_tvm.numpy(), conv_torch, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c1f52e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#练习 3：变换批量矩阵乘法程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c3200c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnumpy_mm_relu_v2(A: np.ndarray, B: np.ndarray, C: np.ndarray):\n",
    "    Y = np.empty((16, 128, 128), dtype=\"float32\")\n",
    "    for n in range(16):\n",
    "        for i in range(128):\n",
    "            for j in range(128):\n",
    "                for k in range(128):\n",
    "                    if k == 0:\n",
    "                        Y[n, i, j] = 0\n",
    "                    Y[n, i, j] = Y[n, i, j] + A[n, i, k] * B[n, k, j]\n",
    "    for n in range(16):\n",
    "        for i in range(128):\n",
    "            for j in range(128):\n",
    "                C[n, i, j] = max(Y[n, i, j], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55e1636e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"nd\">@tvm</span><span class=\"o\">.</span><span class=\"n\">script</span><span class=\"o\">.</span><span class=\"n\">ir_module</span>\n",
       "<span class=\"k\">class</span> <span class=\"nc\">Module</span><span class=\"p\">:</span>\n",
       "    <span class=\"nd\">@T</span><span class=\"o\">.</span><span class=\"n\">prim_func</span>\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">bmm_relu</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">],</span> <span class=\"n\">C</span><span class=\"p\">:</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">Buffer</span><span class=\"p\">[(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">),</span> <span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">]):</span>\n",
       "        <span class=\"c1\"># function attr dict</span>\n",
       "        <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">func_attr</span><span class=\"p\">({</span><span class=\"s2\">&quot;tir.noalias&quot;</span><span class=\"p\">:</span> <span class=\"kc\">True</span><span class=\"p\">,</span> <span class=\"s2\">&quot;global_symbol&quot;</span><span class=\"p\">:</span> <span class=\"s2\">&quot;bmm_relu&quot;</span><span class=\"p\">})</span>\n",
       "        <span class=\"c1\"># body</span>\n",
       "        <span class=\"c1\"># with T.block(&quot;root&quot;)</span>\n",
       "        <span class=\"n\">Y</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">alloc_buffer</span><span class=\"p\">([</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">],</span> <span class=\"n\">dtype</span><span class=\"o\">=</span><span class=\"s2\">&quot;float32&quot;</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"n\">k</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;Y&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">,</span> <span class=\"n\">vk</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SSSR&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">,</span> <span class=\"n\">k</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">],</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">init</span><span class=\"p\">():</span>\n",
       "                    <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">)</span>\n",
       "                <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">A</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">]</span> <span class=\"o\">*</span> <span class=\"n\">B</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vk</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span> <span class=\"ow\">in</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">grid</span><span class=\"p\">(</span><span class=\"mi\">16</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">,</span> <span class=\"mi\">128</span><span class=\"p\">):</span>\n",
       "            <span class=\"k\">with</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">block</span><span class=\"p\">(</span><span class=\"s2\">&quot;C&quot;</span><span class=\"p\">):</span>\n",
       "                <span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">axis</span><span class=\"o\">.</span><span class=\"n\">remap</span><span class=\"p\">(</span><span class=\"s2\">&quot;SSS&quot;</span><span class=\"p\">,</span> <span class=\"p\">[</span><span class=\"n\">n</span><span class=\"p\">,</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">j</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">reads</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">writes</span><span class=\"p\">(</span><span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">])</span>\n",
       "                <span class=\"n\">C</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">max</span><span class=\"p\">(</span><span class=\"n\">Y</span><span class=\"p\">[</span><span class=\"n\">vn</span><span class=\"p\">,</span> <span class=\"n\">vi</span><span class=\"p\">,</span> <span class=\"n\">vj</span><span class=\"p\">],</span> <span class=\"n\">T</span><span class=\"o\">.</span><span class=\"n\">float32</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">))</span>\n",
       "    \n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{n+nd}{@tvm}\\PY{o}{.}\\PY{n}{script}\\PY{o}{.}\\PY{n}{ir\\PYZus{}module}\n",
       "\\PY{k}{class} \\PY{n+nc}{Module}\\PY{p}{:}\n",
       "    \\PY{n+nd}{@T}\\PY{o}{.}\\PY{n}{prim\\PYZus{}func}\n",
       "    \\PY{k}{def} \\PY{n+nf}{bmm\\PYZus{}relu}\\PY{p}{(}\\PY{n}{A}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{,} \\PY{n}{C}\\PY{p}{:} \\PY{n}{T}\\PY{o}{.}\\PY{n}{Buffer}\\PY{p}{[}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{c+c1}{\\PYZsh{} function attr dict}\n",
       "        \\PY{n}{T}\\PY{o}{.}\\PY{n}{func\\PYZus{}attr}\\PY{p}{(}\\PY{p}{\\PYZob{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{tir.noalias}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{k+kc}{True}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{global\\PYZus{}symbol}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{bmm\\PYZus{}relu}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{\\PYZcb{}}\\PY{p}{)}\n",
       "        \\PY{c+c1}{\\PYZsh{} body}\n",
       "        \\PY{c+c1}{\\PYZsh{} with T.block(\\PYZdq{}root\\PYZdq{})}\n",
       "        \\PY{n}{Y} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{alloc\\PYZus{}buffer}\\PY{p}{(}\\PY{p}{[}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{]}\\PY{p}{,} \\PY{n}{dtype}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{float32}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "        \\PY{k}{for} \\PY{n}{n}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{,} \\PY{n}{k} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Y}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{,} \\PY{n}{vk} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SSSR}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{n}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{,} \\PY{n}{k}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{A}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]}\\PY{p}{,} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{init}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "                    \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{)}\n",
       "                \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{+} \\PY{n}{A}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{]} \\PY{o}{*} \\PY{n}{B}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vk}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\n",
       "        \\PY{k}{for} \\PY{n}{n}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j} \\PY{o+ow}{in} \\PY{n}{T}\\PY{o}{.}\\PY{n}{grid}\\PY{p}{(}\\PY{l+m+mi}{16}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{,} \\PY{l+m+mi}{128}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{with} \\PY{n}{T}\\PY{o}{.}\\PY{n}{block}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{C}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{axis}\\PY{o}{.}\\PY{n}{remap}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{SSS}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{p}{[}\\PY{n}{n}\\PY{p}{,} \\PY{n}{i}\\PY{p}{,} \\PY{n}{j}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{reads}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{T}\\PY{o}{.}\\PY{n}{writes}\\PY{p}{(}\\PY{n}{C}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{)}\n",
       "                \\PY{n}{C}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]} \\PY{o}{=} \\PY{n}{T}\\PY{o}{.}\\PY{n}{max}\\PY{p}{(}\\PY{n}{Y}\\PY{p}{[}\\PY{n}{vn}\\PY{p}{,} \\PY{n}{vi}\\PY{p}{,} \\PY{n}{vj}\\PY{p}{]}\\PY{p}{,} \\PY{n}{T}\\PY{o}{.}\\PY{n}{float32}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{)}\\PY{p}{)}\n",
       "    \n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "@tvm.script.ir_module\n",
       "class Module:\n",
       "    @T.prim_func\n",
       "    def bmm_relu(A: T.Buffer[(16, 128, 128), \"float32\"], B: T.Buffer[(16, 128, 128), \"float32\"], C: T.Buffer[(16, 128, 128), \"float32\"]):\n",
       "        # function attr dict\n",
       "        T.func_attr({\"tir.noalias\": True, \"global_symbol\": \"bmm_relu\"})\n",
       "        # body\n",
       "        # with T.block(\"root\")\n",
       "        Y = T.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
       "        for n, i, j, k in T.grid(16, 128, 128, 128):\n",
       "            with T.block(\"Y\"):\n",
       "                vn, vi, vj, vk = T.axis.remap(\"SSSR\", [n, i, j, k])\n",
       "                T.reads(A[vn, vi, vk], B[vn, vk, vj])\n",
       "                T.writes(Y[vn, vi, vj])\n",
       "                with T.init():\n",
       "                    Y[vn, vi, vj] = T.float32(0)\n",
       "                Y[vn, vi, vj] = Y[vn, vi, vj] + A[vn, vi, vk] * B[vn, vk, vj]\n",
       "        for n, i, j in T.grid(16, 128, 128):\n",
       "            with T.block(\"C\"):\n",
       "                vn, vi, vj = T.axis.remap(\"SSS\", [n, i, j])\n",
       "                T.reads(Y[vn, vi, vj])\n",
       "                T.writes(C[vn, vi, vj])\n",
       "                C[vn, vi, vj] = T.max(Y[vn, vi, vj], T.float32(0))\n",
       "    "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tvm.script.ir_module\n",
    "class MyBmmRelu:\n",
    "  @T.prim_func\n",
    "  def bmm_relu(A: T.Buffer[(16, 128, 128), \"float32\"],\n",
    "               B: T.Buffer[(16, 128, 128), \"float32\"],\n",
    "               C: T.Buffer[(16, 128, 128), \"float32\"]):\n",
    "        T.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
    "        # TODO\n",
    "        Y = T.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
    "        for n, i, j, k in T.grid(16, 128, 128, 128):\n",
    "            with T.block(\"Y\"):\n",
    "                vn, vi, vj, vk = T.axis.remap(\"SSSR\", [n, i, j, k])\n",
    "                with T.init():\n",
    "                    Y[vn, vi, vj] = T.float32(0)\n",
    "                Y[vn, vi, vj] = Y[vn, vi, vj] + A[vn, vi, vk] * B[vn, vk, vj]\n",
    "        for n, i, j in T.grid(16, 128, 128):\n",
    "            with T.block(\"C\"):\n",
    "                vn, vi, vj = T.axis.remap(\"SSS\", [n, i, j])\n",
    "                C[vn, vi, vj] = T.max(Y[vn, vi, vj], T.float32(0))\n",
    "                                                      \n",
    "sch = tvm.tir.Schedule(MyBmmRelu)\n",
    "IPython.display.Code(sch.mod.script(), language=\"python\")\n",
    "# Also please validate your result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bc7e8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.script.ir_module\n",
    "class TargetModule:\n",
    "    @T.prim_func\n",
    "    def bmm_relu(A: T.Buffer[(16, 128, 128), \"float32\"], B: T.Buffer[(16, 128, 128), \"float32\"], C: T.Buffer[(16, 128, 128), \"float32\"]) -> None:\n",
    "        T.func_attr({\"global_symbol\": \"bmm_relu\", \"tir.noalias\": True})\n",
    "        Y = T.alloc_buffer([16, 128, 128], dtype=\"float32\")\n",
    "        for i0 in T.parallel(16): #i0 => 16 => n\n",
    "            for i1, i2_0 in T.grid(128, 16): #i1 => 128 => i ; i2_0 => j_0 => (16 * 8) => 16\n",
    "                for ax0_init in T.vectorized(8): # ax0_init => (16 * 8) => 8 => j_1\n",
    "                    with T.block(\"Y_init\"):\n",
    "                        n, i = T.axis.remap(\"SS\", [i0, i1])\n",
    "                        j = T.axis.spatial(128, i2_0 * 8 + ax0_init)\n",
    "                        Y[n, i, j] = T.float32(0)\n",
    "                for ax1_0 in T.serial(32):     #ax1_0 => 32 => k0\n",
    "                    for ax1_1 in T.unroll(4):   #ax1_1 => 4 => k1\n",
    "                        for ax0 in T.serial(8): #ax0 =》 (16 * 8) => 8 => j_1\n",
    "                            with T.block(\"Y_update\"):\n",
    "                                n, i = T.axis.remap(\"SS\", [i0, i1])\n",
    "                                j = T.axis.spatial(128, i2_0 * 8 + ax0)\n",
    "                                k = T.axis.reduce(128, ax1_0 * 4 + ax1_1)\n",
    "                                Y[n, i, j] = Y[n, i, j] + A[n, i, k] * B[n, k, j]\n",
    "                for i2_1 in T.vectorized(8):\n",
    "                    with T.block(\"C\"):\n",
    "                        n, i = T.axis.remap(\"SS\", [i0, i1])\n",
    "                        j = T.axis.spatial(128, i2_0 * 8 + i2_1)\n",
    "                        C[n, i, j] = T.max(Y[n, i, j], T.float32(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e8c815b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n"
     ]
    }
   ],
   "source": [
    "sch = tvm.tir.Schedule(MyBmmRelu)\n",
    "# TODO: transformations\n",
    "# Hints: you can use\n",
    "# `IPython.display.Code(sch.mod.script(), language=\"python\")`\n",
    "# or `print(sch.mod.script())`\n",
    "# to show the current program at any time during the transformation.\n",
    "\n",
    "# Step 1. Get blocks\n",
    "Y = sch.get_block(\"Y\", func_name=\"bmm_relu\")\n",
    "\n",
    "# Step 2. Get loops\n",
    "n, i, j, k = sch.get_loops(Y)\n",
    "\n",
    "# Step 3. Organize the loops\n",
    "j0, j1 = sch.split(j, factors = [None, 8])\n",
    "sch.reorder(n, i, j0, k, j1)\n",
    "n, i, j0, k, j1 = sch.get_loops(Y)\n",
    "sch.parallel(n)\n",
    "C = sch.get_block(\"C\", \"bmm_relu\")\n",
    "sch.reverse_compute_at(C, j0)\n",
    "\n",
    "# Step 4. decompose reduction\n",
    "sch.decompose_reduction(Y, k)\n",
    "\n",
    "# Step 5. vectorize / parallel / unroll\n",
    "Y_init = sch.get_block(\"Y_init\", \"bmm_relu\")\n",
    "ax0_init = sch.get_loops(Y_init)\n",
    "#ax0_init : [tir.LoopRV(0x2385450), tir.LoopRV(0x7a7fe90), tir.LoopRV(0x7a3ae30), tir.LoopRV(0x7941b40)]\n",
    "sch.vectorize(ax0_init[3])\n",
    "\n",
    "C = sch.get_block(\"C\", \"bmm_relu\")\n",
    "ax0 = sch.get_loops(C)\n",
    "sch.vectorize(ax0[3])\n",
    "\n",
    "k0, k1 = sch.split(k, factors = [None, 4])\n",
    "sch.unroll(k1)\n",
    "\n",
    "IPython.display.Code(sch.mod.script(), language=\"python\")\n",
    "tvm.ir.assert_structural_equal(sch.mod, TargetModule)\n",
    "print(\"Pass\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "621aaec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before transformation:\n",
      "Execution time summary:\n",
      " mean (ms)   median (ms)    max (ms)     min (ms)     std (ms)  \n",
      "  37.2572      37.2572      37.2572      37.2572       0.0000   \n",
      "               \n",
      "After transformation:\n",
      "Execution time summary:\n",
      " mean (ms)   median (ms)    max (ms)     min (ms)     std (ms)  \n",
      "   4.3325       4.3325       4.3325       4.3325       0.0000   \n",
      "               \n"
     ]
    }
   ],
   "source": [
    "# 评估变换后的程序的性能\n",
    "before_rt_lib = tvm.build(MyBmmRelu, target=\"llvm\")\n",
    "after_rt_lib = tvm.build(sch.mod, target=\"llvm\")\n",
    "a_tvm = tvm.nd.array(np.random.rand(16, 128, 128).astype(\"float32\"))\n",
    "b_tvm = tvm.nd.array(np.random.rand(16, 128, 128).astype(\"float32\"))\n",
    "c_tvm = tvm.nd.array(np.random.rand(16, 128, 128).astype(\"float32\"))\n",
    "after_rt_lib[\"bmm_relu\"](a_tvm, b_tvm, c_tvm)\n",
    "before_timer = before_rt_lib.time_evaluator(\"bmm_relu\", tvm.cpu())\n",
    "print(\"Before transformation:\")\n",
    "print(before_timer(a_tvm, b_tvm, c_tvm))\n",
    "\n",
    "f_timer = after_rt_lib.time_evaluator(\"bmm_relu\", tvm.cpu())\n",
    "print(\"After transformation:\")\n",
    "print(f_timer(a_tvm, b_tvm, c_tvm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
